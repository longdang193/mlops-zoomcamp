{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scenario 3 (Azure): Team using a remote MLflow server on Azure\n",
        "\n",
        "This scenario demonstrates connecting to a remote MLflow Tracking Server hosted on Azure (e.g., Azure VM), with a production-ready backend database (Azure Database for PostgreSQL) and optional artifact storage on Azure Blob.\n",
        "\n",
        "High-level architecture:\n",
        "- Tracking server: Azure VM (Ubuntu)\n",
        "- Backend store: Azure Database for PostgreSQL (Flexible Server)\n",
        "- Artifact store: local disk on VM (for simplicity) or Azure Blob Storage (optional)\n",
        "\n",
        "You’ll run the MLflow server on the VM, then connect from this notebook via its public IP/DNS.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connect to the remote MLflow server (from this notebook)\n",
        "Fill in your VM public IP/DNS below.\n",
        "\n",
        "**⚠️ Important:** After running the connection cell (Cell 3), if you encounter permission errors when logging artifacts, **restart your Python kernel** and re-run Cell 3. This ensures environment variables are properly set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "# ⚠️ CRITICAL: Must include http:// scheme for remote server\n",
        "tracking_uri = \"http://52.187.178.215:5000\"\n",
        "mlflow.set_tracking_uri(tracking_uri)\n",
        "print(f\"✓ Tracking URI: {mlflow.get_tracking_uri()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import requests\n",
        "\n",
        "start = time.time()\n",
        "response = requests.get(\"http://52.187.178.215:5000\")\n",
        "latency = time.time() - start\n",
        "print(f\"Server response time: {latency:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Only get active experiments (faster)\n",
        "experiments = mlflow.search_experiments(view_type=mlflow.entities.ViewType.ACTIVE_ONLY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List existing experiments\n",
        "Confirm connectivity and see what’s already in the server.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train a model and log to the remote server\n",
        "Logs params, metrics, and a model artifact to the Azure-hosted MLflow server.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "mlflow.set_experiment(\"my-experiment\")\n",
        "\n",
        "with mlflow.start_run():\n",
        "\n",
        "    X, y = load_iris(return_X_y=True)\n",
        "\n",
        "    params = {\"C\": 0.1, \"random_state\": 42}\n",
        "    mlflow.log_params(params)\n",
        "\n",
        "    lr = LogisticRegression(**params).fit(X, y)\n",
        "    y_pred = lr.predict(X)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
        "\n",
        "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
        "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Work with the Model Registry\n",
        "Create a client pointed at the remote server and register the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# Create an MLflow client that connects to your remote tracking server (running on Azure VM)\n",
        "# This must match the same tracking URI used during logging.\n",
        "client = MlflowClient(tracking_uri=\"http://52.187.178.215:5000\")\n",
        "\n",
        "# List all registered models on the server (if any)\n",
        "client.search_registered_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve the latest run from experiment ID \"1\"\n",
        "# This assumes your \"my-experiment\" has ID=1 (you can confirm in the MLflow UI)\n",
        "run = mlflow.search_runs(experiment_ids=[\"1\"]).iloc[0]\n",
        "\n",
        "# Extract the unique run ID from that run to reference its logged artifacts\n",
        "run_id = run.run_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register the logged model in the MLflow Model Registry\n",
        "# This creates a new registered model named \"azure-iris-classifier\" (or updates if it already exists)\n",
        "# 'model_uri' points to the model artifact inside the specific run's folder\n",
        "mlflow.register_model(\n",
        "    model_uri=f\"runs:/{run_id}/models\",\n",
        "    name=\"azure-iris-classifier\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes and troubleshooting\n",
        "- Ensure Postgres allows connections from the VM and requires SSL.\n",
        "- If the UI is unreachable, confirm VM NSG/ports and public IP/DNS.\n",
        "- For artifacts on Azure Blob, ensure the MLflow server has valid credentials and your MLflow version supports the configured scheme.\n",
        "- Use a managed secret store (e.g., Azure Key Vault) for credentials in production.\n",
        "\n",
        "**Artifact directory permissions (on VM):**\n",
        "If you encounter permission errors when the MLflow server tries to write artifacts, ensure the artifact directory is owned by `azureuser`:\n",
        "```bash\n",
        "sudo chown -R azureuser:azureuser /home/azureuser/mlruns-artifacts\n",
        "```\n",
        "The setup script (`setup-mlflow-server.sh`) handles this automatically, but you may need to run this manually if the directory was created differently.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "experiment-tracking",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.24"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
