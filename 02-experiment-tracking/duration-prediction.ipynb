{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2bd82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.24\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41062d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c984c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4add538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b135c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1464985f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/mlops-zoomcamp/02-experiment-tracking/mlruns/1', creation_time=1761828359873, experiment_id='1', last_update_time=1761828359873, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a6e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL = ['PULocationID', 'DOLocationID']\n",
    "NEEDED_COLS = CATEGORICAL + ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'trip_distance']\n",
    "\n",
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename, columns=NEEDED_COLS)\n",
    "\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "    df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[CATEGORICAL] = df[CATEGORICAL].astype(str)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8029eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('/workspaces/mlops-zoomcamp/data/yellow_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('/workspaces/mlops-zoomcamp/data/yellow_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b82eb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>2.10</td>\n",
       "      <td>6.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>14.70</td>\n",
       "      <td>27.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>10.60</td>\n",
       "      <td>15.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>4.94</td>\n",
       "      <td>16.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>224</td>\n",
       "      <td>68</td>\n",
       "      <td>2021-01-01 00:16:29</td>\n",
       "      <td>2021-01-01 00:24:30</td>\n",
       "      <td>1.60</td>\n",
       "      <td>8.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PULocationID DOLocationID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0          142           43  2021-01-01 00:30:10   2021-01-01 00:36:12   \n",
       "2          132          165  2021-01-01 00:43:30   2021-01-01 01:11:06   \n",
       "3          138          132  2021-01-01 00:15:48   2021-01-01 00:31:01   \n",
       "4           68           33  2021-01-01 00:31:49   2021-01-01 00:48:21   \n",
       "5          224           68  2021-01-01 00:16:29   2021-01-01 00:24:30   \n",
       "\n",
       "   trip_distance   duration  \n",
       "0           2.10   6.033333  \n",
       "2          14.70  27.600000  \n",
       "3          10.60  15.216667  \n",
       "4           4.94  16.533333  \n",
       "5           1.60   8.016667  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f2f0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343254, 1340859)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951d51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature 'PU_DO' that combines pickup and dropoff location IDs.\n",
    "# This represents a specific route or trip pattern (e.g., pickup from zone 142 to dropoff at zone 43).\n",
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5cbfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e9fb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3835bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "429e2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = lr.predict(X_val)\n",
    "\n",
    "# np.sqrt(mean_squared_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22bf6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('models/lin_reg.bin', 'wb') as f_out:\n",
    "#     pickle.dump((dv, lr), f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4999b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start a new MLflow run — everything logged inside this block \n",
    "# # will be grouped under the same experiment run in the MLflow UI.\n",
    "# with mlflow.start_run():\n",
    "\n",
    "#     # Tag this run with metadata — useful for filtering or identifying runs later.\n",
    "#     mlflow.set_tag(\"developer\", \"cristian\")\n",
    "\n",
    "#     # Log input data paths as parameters to keep track of which datasets were used for training and validation.\n",
    "#     mlflow.log_param(\"train-data-path\", \"./data/yellow_tripdata_2021-01.parquet\")\n",
    "#     mlflow.log_param(\"valid-data-path\", \"./data/yellow_tripdata_2021-02.parquet\")\n",
    "\n",
    "#     # Define and log the model hyperparameter 'alpha' for the Lasso regression.\n",
    "#     alpha = 0.1\n",
    "#     mlflow.log_param(\"alpha\", alpha)\n",
    "    \n",
    "#     # Initialize and train the Lasso regression model using the training data.\n",
    "#     lr = Lasso(alpha)\n",
    "#     lr.fit(X_train, y_train)\n",
    "\n",
    "#     # Make predictions on the validation dataset.\n",
    "#     y_pred = lr.predict(X_val)\n",
    "\n",
    "#     # Calculate the Root Mean Squared Error (RMSE) to evaluate model performance.\n",
    "#     rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "#     # Log the RMSE metric so it appears in MLflow for comparison across runs.\n",
    "#     mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "#     # Log the trained model file as an artifact — this saves the model binary in the MLflow run directory.\n",
    "#     # 'artifact_path' defines the subfolder within the run's artifact storage.\n",
    "#     mlflow.log_artifact(local_path=\"models/lin_reg.bin\", artifact_path=\"models_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc59e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check current tracking URI\n",
    "# print(\"Tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "# # List all experiments\n",
    "# experiments = mlflow.search_experiments()\n",
    "# for exp in experiments:\n",
    "#     print(f\"Experiment: {exp.name} (ID: {exp.experiment_id})\")\n",
    "\n",
    "# # List runs for a specific experiment\n",
    "# runs = mlflow.search_runs(experiment_ids=[\"1\"])\n",
    "# print(runs[['run_id', 'metrics.rmse', 'params.alpha']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f370f",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with MLflow and Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f56e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "907dc6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "091ab328",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2d84b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function that Hyperopt will minimize.\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Train the XGBoost model with the given parameters.\n",
    "        # 'dtrain' is the training data matrix, 'num_boost_round' is the number of boosting rounds,\n",
    "        # 'evals' is a list of tuples containing the validation data and a name for the evaluation,\n",
    "        # 'early_stopping_rounds' is the number of rounds to wait before stopping if the validation score doesn't improve.\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=20\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "460e11f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 50, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:squarederror',\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b1f77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use Hyperopt to find the best hyperparameters for the XGBoost model.\n",
    "# best_result = fmin(\n",
    "#     fn=objective,          # Objective function to minimize (returns validation RMSE)\n",
    "#     space=search_space,    # The hyperparameter space defined above\n",
    "#     algo=tpe.suggest,      # TPE algorithm: Bayesian optimizer that models p(x|y)\n",
    "#     max_evals=10,          # Number of trials (iterations) to perform\n",
    "#     trials=Trials()        # Object to store details of each run (params, loss, status)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc4d5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable XGBoost autologging to manually control what gets logged to MLflow\n",
    "# (autologging would otherwise record parameters, metrics, and models automatically)\n",
    "mlflow.xgboost.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e8cd729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:8.70473\n",
      "[1]\tvalidation-rmse:8.18719\n",
      "[2]\tvalidation-rmse:7.73507\n",
      "[3]\tvalidation-rmse:7.34101\n",
      "[4]\tvalidation-rmse:6.99911\n",
      "[5]\tvalidation-rmse:6.70309\n",
      "[6]\tvalidation-rmse:6.44805\n",
      "[7]\tvalidation-rmse:6.22863\n",
      "[8]\tvalidation-rmse:6.03993\n",
      "[9]\tvalidation-rmse:5.87898\n",
      "[10]\tvalidation-rmse:5.74031\n",
      "[11]\tvalidation-rmse:5.62193\n",
      "[12]\tvalidation-rmse:5.52015\n",
      "[13]\tvalidation-rmse:5.43335\n",
      "[14]\tvalidation-rmse:5.35946\n",
      "[15]\tvalidation-rmse:5.29515\n",
      "[16]\tvalidation-rmse:5.23961\n",
      "[17]\tvalidation-rmse:5.19222\n",
      "[18]\tvalidation-rmse:5.15073\n",
      "[19]\tvalidation-rmse:5.11507\n",
      "[20]\tvalidation-rmse:5.08359\n",
      "[21]\tvalidation-rmse:5.05622\n",
      "[22]\tvalidation-rmse:5.03200\n",
      "[23]\tvalidation-rmse:5.01159\n",
      "[24]\tvalidation-rmse:4.99262\n",
      "[25]\tvalidation-rmse:4.97618\n",
      "[26]\tvalidation-rmse:4.96099\n",
      "[27]\tvalidation-rmse:4.94774\n",
      "[28]\tvalidation-rmse:4.93420\n",
      "[29]\tvalidation-rmse:4.92215\n",
      "[30]\tvalidation-rmse:4.91162\n",
      "[31]\tvalidation-rmse:4.90200\n",
      "[32]\tvalidation-rmse:4.89302\n",
      "[33]\tvalidation-rmse:4.88474\n",
      "[34]\tvalidation-rmse:4.87804\n",
      "[35]\tvalidation-rmse:4.87151\n",
      "[36]\tvalidation-rmse:4.86540\n",
      "[37]\tvalidation-rmse:4.85944\n",
      "[38]\tvalidation-rmse:4.85371\n",
      "[39]\tvalidation-rmse:4.84821\n",
      "[40]\tvalidation-rmse:4.84322\n",
      "[41]\tvalidation-rmse:4.83769\n",
      "[42]\tvalidation-rmse:4.83308\n",
      "[43]\tvalidation-rmse:4.82879\n",
      "[44]\tvalidation-rmse:4.82454\n",
      "[45]\tvalidation-rmse:4.82083\n",
      "[46]\tvalidation-rmse:4.81737\n",
      "[47]\tvalidation-rmse:4.81364\n",
      "[48]\tvalidation-rmse:4.81076\n",
      "[49]\tvalidation-rmse:4.80763\n",
      "[50]\tvalidation-rmse:4.80469\n",
      "[51]\tvalidation-rmse:4.80151\n",
      "[52]\tvalidation-rmse:4.79841\n",
      "[53]\tvalidation-rmse:4.79539\n",
      "[54]\tvalidation-rmse:4.79308\n",
      "[55]\tvalidation-rmse:4.79109\n",
      "[56]\tvalidation-rmse:4.78876\n",
      "[57]\tvalidation-rmse:4.78694\n",
      "[58]\tvalidation-rmse:4.78372\n",
      "[59]\tvalidation-rmse:4.78176\n",
      "[60]\tvalidation-rmse:4.77959\n",
      "[61]\tvalidation-rmse:4.77742\n",
      "[62]\tvalidation-rmse:4.77521\n",
      "[63]\tvalidation-rmse:4.77374\n",
      "[64]\tvalidation-rmse:4.77191\n",
      "[65]\tvalidation-rmse:4.77055\n",
      "[66]\tvalidation-rmse:4.76890\n",
      "[67]\tvalidation-rmse:4.76749\n",
      "[68]\tvalidation-rmse:4.76584\n",
      "[69]\tvalidation-rmse:4.76455\n",
      "[70]\tvalidation-rmse:4.76306\n",
      "[71]\tvalidation-rmse:4.76122\n",
      "[72]\tvalidation-rmse:4.75976\n",
      "[73]\tvalidation-rmse:4.75827\n",
      "[74]\tvalidation-rmse:4.75664\n",
      "[75]\tvalidation-rmse:4.75520\n",
      "[76]\tvalidation-rmse:4.75419\n",
      "[77]\tvalidation-rmse:4.75295\n",
      "[78]\tvalidation-rmse:4.75191\n",
      "[79]\tvalidation-rmse:4.75037\n",
      "[80]\tvalidation-rmse:4.74920\n",
      "[81]\tvalidation-rmse:4.74830\n",
      "[82]\tvalidation-rmse:4.74708\n",
      "[83]\tvalidation-rmse:4.74608\n",
      "[84]\tvalidation-rmse:4.74504\n",
      "[85]\tvalidation-rmse:4.74425\n",
      "[86]\tvalidation-rmse:4.74302\n",
      "[87]\tvalidation-rmse:4.74200\n",
      "[88]\tvalidation-rmse:4.74090\n",
      "[89]\tvalidation-rmse:4.73996\n",
      "[90]\tvalidation-rmse:4.73889\n",
      "[91]\tvalidation-rmse:4.73784\n",
      "[92]\tvalidation-rmse:4.73689\n",
      "[93]\tvalidation-rmse:4.73583\n",
      "[94]\tvalidation-rmse:4.73465\n",
      "[95]\tvalidation-rmse:4.73351\n",
      "[96]\tvalidation-rmse:4.73230\n",
      "[97]\tvalidation-rmse:4.73133\n",
      "[98]\tvalidation-rmse:4.73045\n",
      "[99]\tvalidation-rmse:4.72979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:06:30] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models import infer_signature\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Convert NumPy arrays or DataFrames into XGBoost's optimized DMatrix format\n",
    "    # This structure improves memory efficiency and training performance    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    # Define the best hyperparameters found from hyperparameter tuning (e.g., Hyperopt)\n",
    "    # These control model complexity, learning rate, regularization, and random seed\n",
    "    best_params = {\n",
    "        'learning_rate': 0.09585355369315604,\n",
    "        'max_depth': 30,\n",
    "        'min_child_weight': 1.060597050922164,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'reg_alpha': 0.018060244040060163,\n",
    "        'reg_lambda': 0.011658731377413597,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    # Log all chosen hyperparameters to MLflow for reproducibility\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Train the XGBoost model using the defined parameters\n",
    "    # - num_boost_round: maximum number of boosting iterations\n",
    "    # - evals: list of evaluation datasets (train/validation) to track performance\n",
    "    # - early_stopping_rounds: stop training if validation metric doesn’t improve for 20 rounds\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=100,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "\n",
    "    # Make predictions on the validation dataset\n",
    "    y_pred = booster.predict(valid)\n",
    "\n",
    "    # Calculate the Root Mean Squared Error (RMSE) to evaluate model performance\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "    # Log the RMSE metric so it appears in MLflow for comparison across runs\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Save the preprocessor (feature transformation model) as a pickle file\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    # Log the preprocessor as an artifact in MLflow\n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # The signature defines the input and output schema for the model\n",
    "    signature = infer_signature(X_val, y_pred)\n",
    "\n",
    "    # Log the trained XGBoost model in MLflow with signature and input example\n",
    "    input_example = X_val[:3]\n",
    "    mlflow.xgboost.log_model(\n",
    "        booster, \n",
    "        artifact_path=\"models_mlflow\",  # Path within the artifacts folder\n",
    "        input_example=input_example\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4979b6",
   "metadata": {},
   "source": [
    "## Logging Model with Signature for Predictions\n",
    "\n",
    "To see the \"Make Predictions\" section in MLflow UI, you need to log the model with a **signature** that defines input/output schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2785be69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:8.70473\n",
      "[1]\tvalidation-rmse:8.18719\n",
      "[2]\tvalidation-rmse:7.73507\n",
      "[3]\tvalidation-rmse:7.34101\n",
      "[4]\tvalidation-rmse:6.99911\n",
      "[5]\tvalidation-rmse:6.70309\n",
      "[6]\tvalidation-rmse:6.44805\n",
      "[7]\tvalidation-rmse:6.22863\n",
      "[8]\tvalidation-rmse:6.03993\n",
      "[9]\tvalidation-rmse:5.87898\n",
      "[10]\tvalidation-rmse:5.74031\n",
      "[11]\tvalidation-rmse:5.62193\n",
      "[12]\tvalidation-rmse:5.52015\n",
      "[13]\tvalidation-rmse:5.43335\n",
      "[14]\tvalidation-rmse:5.35946\n",
      "[15]\tvalidation-rmse:5.29515\n",
      "[16]\tvalidation-rmse:5.23961\n",
      "[17]\tvalidation-rmse:5.19222\n",
      "[18]\tvalidation-rmse:5.15073\n",
      "[19]\tvalidation-rmse:5.11507\n",
      "[20]\tvalidation-rmse:5.08359\n",
      "[21]\tvalidation-rmse:5.05622\n",
      "[22]\tvalidation-rmse:5.03200\n",
      "[23]\tvalidation-rmse:5.01159\n",
      "[24]\tvalidation-rmse:4.99262\n",
      "[25]\tvalidation-rmse:4.97618\n",
      "[26]\tvalidation-rmse:4.96099\n",
      "[27]\tvalidation-rmse:4.94774\n",
      "[28]\tvalidation-rmse:4.93420\n",
      "[29]\tvalidation-rmse:4.92215\n",
      "[30]\tvalidation-rmse:4.91162\n",
      "[31]\tvalidation-rmse:4.90200\n",
      "[32]\tvalidation-rmse:4.89302\n",
      "[33]\tvalidation-rmse:4.88474\n",
      "[34]\tvalidation-rmse:4.87804\n",
      "[35]\tvalidation-rmse:4.87151\n",
      "[36]\tvalidation-rmse:4.86540\n",
      "[37]\tvalidation-rmse:4.85944\n",
      "[38]\tvalidation-rmse:4.85371\n",
      "[39]\tvalidation-rmse:4.84821\n",
      "[40]\tvalidation-rmse:4.84322\n",
      "[41]\tvalidation-rmse:4.83769\n",
      "[42]\tvalidation-rmse:4.83308\n",
      "[43]\tvalidation-rmse:4.82879\n",
      "[44]\tvalidation-rmse:4.82454\n",
      "[45]\tvalidation-rmse:4.82083\n",
      "[46]\tvalidation-rmse:4.81737\n",
      "[47]\tvalidation-rmse:4.81364\n",
      "[48]\tvalidation-rmse:4.81076\n",
      "[49]\tvalidation-rmse:4.80763\n",
      "[50]\tvalidation-rmse:4.80469\n",
      "[51]\tvalidation-rmse:4.80151\n",
      "[52]\tvalidation-rmse:4.79841\n",
      "[53]\tvalidation-rmse:4.79539\n",
      "[54]\tvalidation-rmse:4.79308\n",
      "[55]\tvalidation-rmse:4.79109\n",
      "[56]\tvalidation-rmse:4.78876\n",
      "[57]\tvalidation-rmse:4.78694\n",
      "[58]\tvalidation-rmse:4.78372\n",
      "[59]\tvalidation-rmse:4.78176\n",
      "[60]\tvalidation-rmse:4.77959\n",
      "[61]\tvalidation-rmse:4.77742\n",
      "[62]\tvalidation-rmse:4.77521\n",
      "[63]\tvalidation-rmse:4.77374\n",
      "[64]\tvalidation-rmse:4.77191\n",
      "[65]\tvalidation-rmse:4.77055\n",
      "[66]\tvalidation-rmse:4.76890\n",
      "[67]\tvalidation-rmse:4.76749\n",
      "[68]\tvalidation-rmse:4.76584\n",
      "[69]\tvalidation-rmse:4.76455\n",
      "[70]\tvalidation-rmse:4.76306\n",
      "[71]\tvalidation-rmse:4.76122\n",
      "[72]\tvalidation-rmse:4.75976\n",
      "[73]\tvalidation-rmse:4.75827\n",
      "[74]\tvalidation-rmse:4.75664\n",
      "[75]\tvalidation-rmse:4.75520\n",
      "[76]\tvalidation-rmse:4.75419\n",
      "[77]\tvalidation-rmse:4.75295\n",
      "[78]\tvalidation-rmse:4.75191\n",
      "[79]\tvalidation-rmse:4.75037\n",
      "[80]\tvalidation-rmse:4.74920\n",
      "[81]\tvalidation-rmse:4.74830\n",
      "[82]\tvalidation-rmse:4.74708\n",
      "[83]\tvalidation-rmse:4.74608\n",
      "[84]\tvalidation-rmse:4.74504\n",
      "[85]\tvalidation-rmse:4.74425\n",
      "[86]\tvalidation-rmse:4.74302\n",
      "[87]\tvalidation-rmse:4.74200\n",
      "[88]\tvalidation-rmse:4.74090\n",
      "[89]\tvalidation-rmse:4.73996\n",
      "[90]\tvalidation-rmse:4.73889\n",
      "[91]\tvalidation-rmse:4.73784\n",
      "[92]\tvalidation-rmse:4.73689\n",
      "[93]\tvalidation-rmse:4.73583\n",
      "[94]\tvalidation-rmse:4.73465\n",
      "[95]\tvalidation-rmse:4.73351\n",
      "[96]\tvalidation-rmse:4.73230\n",
      "[97]\tvalidation-rmse:4.73133\n",
      "[98]\tvalidation-rmse:4.73045\n",
      "[99]\tvalidation-rmse:4.72979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/30 11:10:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/home/codespace/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [11:10:21] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 3f9865448f1540b69b325dc61ef5dba6\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models import infer_signature\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    best_params = {\n",
    "        'learning_rate': 0.09585355369315604,\n",
    "        'max_depth': 30,\n",
    "        'min_child_weight': 1.060597050922164,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'reg_alpha': 0.018060244040060163,\n",
    "        'reg_lambda': 0.011658731377413597,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=100,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Save the preprocessor\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # === KEY DIFFERENCE: Infer signature from input/output ===\n",
    "    # The signature defines the input and output schema for the model\n",
    "    # This is what enables the \"Make Predictions\" section in MLflow UI\n",
    "    signature = infer_signature(X_val, y_pred)\n",
    "\n",
    "    # Log the model with BOTH signature and input_example\n",
    "    # Convert sparse matrix to dense array for input_example to avoid serialization issues\n",
    "    input_example = X_val[:3].toarray() if hasattr(X_val, 'toarray') else X_val[:3]\n",
    "    mlflow.xgboost.log_model(\n",
    "        booster, \n",
    "        artifact_path=\"models_mlflow\",\n",
    "        signature=signature,  # <-- This is the key!\n",
    "        input_example=input_example\n",
    "    )\n",
    "    \n",
    "    print(f\"Run ID: {mlflow.active_run().info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87614b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/30 09:47:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: Unable to allocate 273. GiB for an array with shape (1343254, 27306) and data type float64\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "# from sklearn.svm import LinearSVR\n",
    "\n",
    "# # Enable automatic MLflow logging for all scikit-learn models\n",
    "# # This logs:\n",
    "# #   - Model parameters (e.g., n_estimators, max_depth)\n",
    "# #   - Evaluation metrics (e.g., RMSE)\n",
    "# #   - Trained model artifacts (serialized .pkl files)\n",
    "# #   - Model signature and environment info (for reproducibility)\n",
    "# mlflow.sklearn.autolog()\n",
    "\n",
    "# # Loop through multiple model classes to train and compare them easily\n",
    "# # Each iteration will:\n",
    "# #   1. Start a new MLflow run\n",
    "# #   2. Train one model\n",
    "# #   3. Evaluate it\n",
    "# #   4. Log results to MLflow automatically\n",
    "# for model_class in (RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, LinearSVR):\n",
    "\n",
    "#     with mlflow.start_run():\n",
    "        \n",
    "#         # Log paths to the training and validation datasets for reproducibility\n",
    "#         mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2022-01.parquet\")\n",
    "#         mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2022-02.parquet\")\n",
    "\n",
    "#         # Log the preprocessor as an artifact in MLflow\n",
    "#         mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "#         # Initialize and train the model\n",
    "#         mlmodel = model_class()\n",
    "#         mlmodel.fit(X_train, y_train)\n",
    "\n",
    "#         # Make predictions on the validation dataset\n",
    "#         y_pred = mlmodel.predict(X_val)\n",
    "#         rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "#         # Log the RMSE metric to MLflow for comparison across runs\n",
    "#         mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11711e64",
   "metadata": {},
   "source": [
    "## Loading the Model as a Native XGBoost Object: Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Define the model URI (Uniform Resource Identifier).\n",
    "# This string points to a specific model stored in MLflow.\n",
    "logged_model = 'runs:/712e9c4fb3294a75bd60b15f76102062/models_mlflow'\n",
    "\n",
    "# Load the model using MLflow’s PyFunc interface/flavor.\n",
    "# This loads the model as a generic Python function (PyFuncModel),\n",
    "# which can make predictions on pandas DataFrames and other supported input types.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7edb369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: models_mlflow\n",
       "  flavor: mlflow.xgboost\n",
       "  run_id: 712e9c4fb3294a75bd60b15f76102062"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3ca64b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.896988   8.88484   21.050125  13.681334   4.0140877 10.455057\n",
      " 41.32619   21.868849  10.650156   4.305702 ]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using RAW data (not DMatrix)\n",
    "y_pred_pyfunc = loaded_model.predict(X_val)\n",
    "\n",
    "# View predictions\n",
    "print(y_pred_pyfunc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loads the same model, but using the XGBoost flavor.\n",
    "xgboost_model = mlflow.xgboost.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ed1172a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x77566dbc33d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "debbf63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca148302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.896988 ,  8.88484  , 21.050125 , 13.681334 ,  4.0140877,\n",
       "       10.455057 , 41.32619  , 21.868849 , 10.650156 ,  4.305702 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first 10\n",
    "y_pred[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiment-tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
